# What is Differential Privacy?

## Definition
Privacy is one important human right, but it doesn't mean it is easy to preserve it. It is actually really difficult. In order to systematize and formalize the preservation of privacy, the Differential Privacy constraints were developed.

There is a mathematical definition for it, that can be intimidating at first. But don't worry, we're going to make it as intuitive as possible. Let's start with some formulas and then dissect it into smaller and more comprehensible parts.

```
A mechanism M with domain N|ğ’³| is ğœ€-differentially private if for all ğ’® âŠ† ğ‘…ğ‘ğ‘›ğ‘”ğ‘’(M) and for all ğ‘¥, ğ‘¦ âˆˆ N|ğ’³| such that ||ğ‘¥ âˆ’ ğ‘¦|| â‰¤ 1:

ğ‘ƒ[M(ğ‘¥) âˆˆ ğ’®]/ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®] â‰¤ exp(ğœ€)

In this definition, we have ğ‘ƒ[ğ¸] as the probability of a certain event ğ¸ happening and ||ğ‘¥|| is the sum of the absolute value of all dimentions of ğ‘¥.
```

This mechanism is a way of adding noise to the data. It means that it will draw a random value from a random variable. You can imagine this mechanism as a way of lottery of values. It can, for instance, raffle values from -1 to 1.

For a better understading of this definition, let's imagine you have two inputs of a datasets (or two lines in a database) ğ‘¥, ğ‘¦. And they are almost identical, except for one value. And then we raffle a random value from the DP Mechanism â€“ the lottery we described earlier. This raffled value, we add to each of the ğ‘¥ and ğ‘¦ columns. After that, we compare the two results M(ğ‘¥) and M(ğ‘¦).

If the Mechanism (lottery) always outputs zero, then M(ğ‘¥)=ğ‘¥ and M(ğ‘¦)=ğ‘¦. And, as ğ‘¥ and ğ‘¦ already differ by one value, M(ğ‘¥) and M(ğ‘¦) will be different as well. In this case, the probability of M(ğ‘¥) and M(ğ‘¦) being the same is zero. With this in mind, ğ‘ƒ[M(ğ‘¥) âˆˆ ğ’®] and ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®] will be hugely different values. So the value of `ğ‘ƒ[M(ğ‘¥) âˆˆ ğ’®]/ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®]` has no upper limit, since ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®] can be zero. This is the case were there is no privacy at all, because the mechanism doesn't change anything in the input. We see that when ğœ€â†’âˆ, privacy is zero.

Now imagine that all ğ‘¥ and ğ‘¦ columns have values ranging from 0 to 1. And that the mechanism we use this time, outputs a value between -100 and +100 (you can imagine an uniform distribution). In this case the noise is huge, and its values usually are way greater than the input values. So when we add the noise to the input, the resulting value will depend more on the noise than the input itself. So ğ‘ƒ[M(ğ‘¥) âˆˆ ğ’®] and ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®] will be closer values. Because of that, `ğ‘ƒ[M(ğ‘¥) âˆˆ ğ’®]/ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®]` will be closer to 1. With that, we can see that when ğœ€â†’0 (or simply ğ‘ƒ[M(ğ‘¥) âˆˆ ğ’®]/ğ‘ƒ[M(ğ‘¦) âˆˆ ğ’®] â†’ 1), privacy is at its best!